# Day 10 ‚Äì 08-07-2025 (Tuesday)
**Smart Fusion Training ‚Äì Week 2**

## Topics Covered:
- Introduction to Unsupervised Learning
- Clustering and its types
- K-Means Clustering Algorithm
- Step-by-step working of K-Means
- Applications of Clustering
- Hands-on example of K-Means using Python

##  Concepts Learned:
- Clustering is used when we don‚Äôt have labels or target values.
- **K-Means Clustering** groups data into K clusters based on distance.
- Steps involved in K-Means:
  1. Choose K (number of clusters)
  2. Initialize K centroids randomly
  3. Assign each point to the closest centroid
  4. Recalculate centroids (mean of all points in cluster)
  5. Repeat steps 3‚Äì4 until centroids don‚Äôt change
- Distance used is typically **Euclidean distance**.
- K-Means works best when clusters are spherical and well separated.
- Real-life applications include:
  - Customer segmentation
  - Market analysis
  - Pattern recognition
  - Grouping sensor behaviors

##  Tools / Platforms Used:
- Google Colab / Jupyter Notebook
- Libraries: `sklearn`, `matplotlib`, `numpy`

## üõ†Ô∏è Tasks Performed:
- Created sample dataset (e.g., age vs. spending score)
- Applied `KMeans` from `sklearn.cluster`
- Visualized clusters and centroids using scatter plots
- Experimented with different values of K (e.g., K=2, K=3)

## ‚úÖ Task Given:
- Apply K-Means on a dataset with at least two features
- Visualize clusters with centroids



## Reflections:
K-Means was easy to understand and interesting to visualize. I enjoyed seeing how data gets grouped based on similarity. I now understand the power of unsupervised learning. Looking forward to learning how to choose the best number of clusters using the Elbow Method.
